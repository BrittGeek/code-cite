{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Code References from papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook:\n",
    "\n",
    " * Uses getpapers externally to download fulltext of all papers in EuPMC which contain github URLs\n",
    " * Textmines each paper fulltext and extract occurences of GitHub URLs\n",
    " * Outputs a data structure of the form: paper_DOI {{github_url: \"http://github.com/blah/blah\"}...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from lxml import etree\n",
    "import re\n",
    "import process_eupmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use getpapers to download fulltext of papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently do this outside of the notebook, and assume that the files are available locally.\n",
    "\n",
    "The command we are using is:\n",
    "\n",
    ">getpapers --query 'github' -x --limit 100 -o data\n",
    "\n",
    "which queries EuPMC for all papers containing the term 'github' and returns the full text of the first 100 papers matching this into the directory 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textmine each paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the data\n",
    "data_dir = '../data'\n",
    "\n",
    "# File containing the list of matching papers\n",
    "matching_papers = data_dir + '/' + 'eupmc_fulltext_html_urls.txt'\n",
    "\n",
    "# Name of the Content Mine results file in each paper subdirectory\n",
    "contentmine_results = 'eupmc_result.json'\n",
    "\n",
    "# Name of the Content Mine full text xml paper dump in each paper subdirectory\n",
    "fulltext_xml = 'fulltext.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object for building the JSON output file containing the dictionary of papers and URLs to repositories\n",
    "\n",
    "dict_of_papers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PMC5802054', 'PMC5838108', 'PMC5833151', 'PMC5634325', 'PMC5832410', 'PMC5764482', 'PMC5819480', 'PMC5627421', 'PMC5753347', 'PMC5736641']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of subdirectories dumped by ContentMine\n",
    "papers = process_eupmc.get_paper_subdirectories(matching_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each paper\n",
    "\n",
    "for paper_dir in papers:\n",
    "\n",
    "    paper_dict = {}\n",
    " \n",
    "    # Read in the JSON file and get the DOI\n",
    "    \n",
    "    filename = data_dir + '/' + paper_dir + '/' + contentmine_results\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            paper_json = json.load(f)\n",
    "            # Get the DOI\n",
    "            paper_doi = paper_json['doi'][0]\n",
    "            pub_date = paper_json['journalInfo'][0]['printPublicationDate'][0]\n",
    "    except IOError:\n",
    "        print(\"Error: File does not appear to exist.\")\n",
    "    \n",
    "    # Read in the XML full text and mine for the github URLs\n",
    "\n",
    "    fulltext_file = data_dir + '/' + paper_dir + '/' + fulltext_xml\n",
    " \n",
    "    gh_urls = []\n",
    "\n",
    "    try:\n",
    "        with open(fulltext_file, 'r') as f:\n",
    "            data = f.read()\n",
    "            urls = re.findall(r'(https?://\\S+)(?=\\\")', data)\n",
    "            for url in urls:\n",
    "                if re.match(r'https?://github.com', url):\n",
    " #                   print(url)\n",
    "                    gh_urls.append(url) \n",
    "    except IOError:\n",
    "        print(\"Error: File does not appear to exist.\")\n",
    "\n",
    "    \n",
    "    paper_dict['pub_date'] = pub_date\n",
    "    paper_dict['github'] = gh_urls\n",
    "\n",
    "    dict_of_papers[str(paper_doi)] = paper_dict    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_of_papers.json', 'w') as outfile:  \n",
    "    json.dump(dict_of_papers, outfile)\n",
    "\n",
    "print(json.dumps(dict_of_papers, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
