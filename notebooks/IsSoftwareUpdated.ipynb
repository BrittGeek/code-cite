{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is Software Updated?\n",
    "\n",
    "This notebook looks at references to GitHub URLs in papers available in the OA corpus from EuroPMC,\n",
    "and identifies:\n",
    "\n",
    "  * How many times the GitHub repositories have been updated since paper referencing them was released\n",
    "  \n",
    "Note that at present, we are not distinguishing between URLs referencing software *created* by the paper authors,\n",
    "versus *used* by the authors, nor which software was created as a result of the work in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from github import Github\n",
    "\n",
    "import process_eupmc\n",
    "import process_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the data\n",
    "data_dir = '../data'\n",
    "\n",
    "# File containing the list of matching papers\n",
    "matching_papers = data_dir + '/' + 'eupmc_fulltext_html_urls.txt'\n",
    "\n",
    "# File for the output\n",
    "output_jsonfile = data_dir + '/' + 'dict_of_papers.json'\n",
    "\n",
    "# Github Token\n",
    "gh_token = '../secrets/github_token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gh_token, 'r') as f:\n",
    "    github_token = f.read().rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use getpapers to download fulltext of papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently do this outside of the notebook, and assume that the files are available locally.\n",
    "\n",
    "The command we are using is:\n",
    "\n",
    ">getpapers --query 'github' -x --limit 100 -o data\n",
    "\n",
    "which queries EuPMC for all papers containing the term 'github' and returns the full text of the first 100 papers matching this into the directory 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textmine each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of subdirectories dumped by ContentMine\n",
    "paper_ids = process_eupmc.get_pmcids(matching_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the papers and extract all the references to GitHub and Zenodo urls\n",
    "papers_info = process_eupmc.process_papers(paper_ids, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_papers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in papers_info:\n",
    "    paper_dict = {}\n",
    "    paper_dict['pmcid'] = p.pmcid\n",
    "    paper_dict['pub_date'] = p.pub_date\n",
    "    paper_dict['github'] = p.references['github']\n",
    "    dict_of_papers[str(p.doi)] = paper_dict    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse GitHub repos to see frequency of commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Github(github_token)\n",
    "number_of_updates = {}\n",
    "\n",
    "for p in papers_info:\n",
    "\n",
    "    repos = []\n",
    "    for gh_url in p.references['github']:\n",
    "        words = gh_url.split('/')\n",
    "        if len(words) > 4:\n",
    "            reponame = words[3] + '/' + words[4]\n",
    "            if reponame not in repos:\n",
    "                repos.append(reponame)            \n",
    "\n",
    "\n",
    "    \n",
    "    for repo in repos:\n",
    "        print (\"Processing: \", repo)\n",
    "        code = g.get_repo(repo)\n",
    "        # limit to commits since publication date\n",
    "        since = datetime.strptime(p.pub_date, '%Y-%m-%d')\n",
    "        commits = code.get_commits()\n",
    "        num_commits = 0\n",
    "        commit_date = commits[num_commits].commit.author.date\n",
    "        while commit_date > since:\n",
    "            num_commits = num_commits + 1\n",
    "            commit_date = commits[num_commits].commit.author.date\n",
    "        print(\"Number of commits since publication: \", num_commits)\n",
    "        number_of_updates[repo] = num_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AllonKleinLab/SPRING': 5,\n",
       " 'BIC-MNI/minc-toolkit': 0,\n",
       " 'ChimeRScope/ChimeRScope': 0,\n",
       " 'ChrisMaherLab/INTEGRATE-Vis': 2,\n",
       " 'DmitryUlyanov/Multicore-TSNE': 1,\n",
       " 'GGiecold/ECLAIR': 0,\n",
       " 'Huiyang520/DMk-BKmeans': 0,\n",
       " 'MaayanLab/CCLE_Clustergrammer': 0,\n",
       " 'MaayanLab/CST_Lung_Cancer_Viz': 0,\n",
       " 'MaayanLab/Cytof_Plasma_PMA': 0,\n",
       " 'MaayanLab/clustergrammer': 12,\n",
       " 'MaayanLab/clustergrammer-docs': 6,\n",
       " 'MaayanLab/clustergrammer-py': 0,\n",
       " 'MaayanLab/clustergrammer-web': 4,\n",
       " 'MaayanLab/clustergrammer-widget': 5,\n",
       " 'PMBio/scLVM': 0,\n",
       " 'Planteome/amigo': 0,\n",
       " 'Planteome/common-files-for-ref-ontologies': 0,\n",
       " 'Planteome/plant-experimental-conditions-ontology': 21,\n",
       " 'Planteome/plant-ontology': 13,\n",
       " 'Planteome/plant-trait-ontology': 89,\n",
       " 'Planteome/planteome-ncbi-taxonomy': 0,\n",
       " 'SheffieldML/GPy': 48,\n",
       " 'WGLab/lncScore': 0,\n",
       " 'YeatmanLab/AFQ-Browser': 0,\n",
       " 'YeatmanLab/AFQ-Browser_data': 0,\n",
       " 'YosefLab/FastProject': 0,\n",
       " 'asncd/MIMOSCA': 0,\n",
       " 'aziele/alfpy': 2,\n",
       " 'bioinfo-ut/GenomeTester4': 13,\n",
       " 'biolink/biolink-api': 20,\n",
       " 'bioperl/p5-bpwrapper': 1,\n",
       " 'cbib/MICADo': 0,\n",
       " 'congyingnan/TF-IDF': 0,\n",
       " 'ctlab/metafast': 0,\n",
       " 'cyinbox/PPI': 0,\n",
       " 'danielnavarrogomez/phy-mer': 2,\n",
       " 'dhimmel/scopus': 0,\n",
       " 'dimenwarper/scimitar': 0,\n",
       " 'elifesciences-publications/crossref': 0,\n",
       " 'elifesciences-publications/library-access': 0,\n",
       " 'elifesciences-publications/scihub': 0,\n",
       " 'elifesciences-publications/scihub-manuscript': 0,\n",
       " 'elifesciences-publications/scopus': 0,\n",
       " 'evolbioinf/andi': 22,\n",
       " 'fanhuan/AAF': 14,\n",
       " 'gmarcais/Quorum': 0,\n",
       " 'greenelab/crossref': 0,\n",
       " 'greenelab/library-access': 2,\n",
       " 'greenelab/opencitations': 0,\n",
       " 'greenelab/scihub': 1,\n",
       " 'greenelab/scihub-browser-data': 0,\n",
       " 'greenelab/scihub-manuscript': 0,\n",
       " 'igm-team/orion-public': 0,\n",
       " 'jacoblevine/PhenoGraph': 0,\n",
       " 'jessieren/VirHostMatcher': 2,\n",
       " 'jupyter-widgets/ipywidgets': 39,\n",
       " 'jupyter-widgets/widget-cookiecutter': 4,\n",
       " 'lh3/miniasm': 2,\n",
       " 'lh3/minimap': 0,\n",
       " 'linnarsson-lab/loompy': 34,\n",
       " 'luscinius/afcluster': 0,\n",
       " 'marbl/MHAP': 2,\n",
       " 'marbl/mash': 13,\n",
       " 'mourisl/Lighter': 1,\n",
       " 'mrdoob/three.js': 306,\n",
       " 'npnl/ATLAS': 0,\n",
       " 'npnl/SRQL': 0,\n",
       " 'pandas-dev/pandas': 321,\n",
       " 'pato-ontology/pato': 12,\n",
       " 'pdtrang/GSM': 0,\n",
       " 'seqan/seqan': 107,\n",
       " 'shaze/wcdest': 0,\n",
       " 'soedinglab/kClust': 0,\n",
       " 'tderrien/FEELnc': 9,\n",
       " 'theislab/Scanpy': 174,\n",
       " 'theislab/anndata': 57,\n",
       " 'theislab/scanpy': 174,\n",
       " 'theislab/scanpy_usage': 25,\n",
       " 'tlawrence3/FAST': 0,\n",
       " 'vals/umis': 0,\n",
       " 'warrenlr/LINKS': 11,\n",
       " 'yeatmanlab/AFQ-Browser-MSexample': 0,\n",
       " 'yeatmanlab/AFQ-Browser_data': 0,\n",
       " 'yeatmanlab/AFQBrowser-demo': 0,\n",
       " 'yeatmanlab/Sarica_2017': 0,\n",
       " 'yeolab/flotilla': 0,\n",
       " 'younglululu/CAFE': 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
